#!/usr/bin/env python3
"""
ç‹¼äººæ€æ¯”èµ›åˆ†æè„šæœ¬ - ä½¿ç”¨OpenAI APIè¿›è¡Œå‘è¨€åˆ†æ
ç®€åŒ–ç‰ˆï¼šåªéœ€è¦ASRæ—¥å¿—ä½œä¸ºè¾“å…¥ï¼Œå…¶ä½™é…ç½®ä».envè¯»å–
"""

import os
import json
import argparse
from typing import Dict, Any, List
from volcenginesdkarkruntime import Ark
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()


def load_prompts():
    """åŠ è½½ pmt.py ä¸­çš„ prompt"""
    import pmt
    return pmt.sys_prompt, pmt.user_prompt


def load_board_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½ç‰ˆå‹é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def load_asr_log(asr_log_path: str) -> Dict[str, Any]:
    """åŠ è½½ASRæ—¥å¿—æ–‡ä»¶"""
    with open(asr_log_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def extract_section_from_asr(
    asr_data: Dict[str, Any],
    start_label: str = None,
    end_label: str = None
) -> str:
    """ä»ASRæ—¥å¿—ä¸­æå–æŒ‡å®šæ—¶é—´æ®µçš„å¯¹è¯è®°å½•

    Args:
        asr_data: ASRæ—¥å¿—æ•°æ®
        start_label: å¼€å§‹æ ‡ç­¾ï¼ˆå¦‚æœä¸ºNoneï¼Œä»å¤´å¼€å§‹ï¼‰
        end_label: ç»“æŸæ ‡ç­¾ï¼ˆå¦‚æœä¸ºNoneï¼Œæå–åˆ°æœ«å°¾æˆ–ä¸‹ä¸€ä¸ªæ ‡è®°ï¼‰

    Returns:
        æå–çš„å¯¹è¯è®°å½•æ–‡æœ¬
    """
    merged_segments = asr_data.get('merged_segments', [])
    time_marks = asr_data.get('time_marks', [])

    if start_label is None:
        # æå–æ‰€æœ‰å¯¹è¯
        transcript_lines = []
        for segment in merged_segments:
            speaker = segment.get('display_speaker', segment.get('speaker', 'æœªçŸ¥'))
            text = segment.get('text', '')
            start_time = segment.get('start', '')
            end_time = segment.get('end', '')
            transcript_lines.append(f"[{start_time}-{end_time}] {speaker}: {text}")
        return '\n'.join(transcript_lines)

    # æ‰¾åˆ°å¼€å§‹å’Œç»“æŸçš„æ—¶é—´ç‚¹
    start_ms = None
    end_ms = None

    for mark in time_marks:
        if start_label in mark.get('label', ''):
            start_ms = mark['start_ms']
        elif end_label and end_label in mark.get('label', ''):
            end_ms = mark['start_ms']
            break

    if start_ms is None:
        raise ValueError(f"æœªæ‰¾åˆ°å¼€å§‹æ ‡ç­¾: {start_label}")

    # å¦‚æœæ²¡æœ‰æŒ‡å®šç»“æŸæ ‡ç­¾ï¼Œæ‰¾åˆ°ä¸‹ä¸€ä¸ªæ ‡è®°ä½œä¸ºç»“æŸç‚¹
    if end_ms is None and end_label is None:
        for mark in time_marks:
            if mark['start_ms'] > start_ms:
                end_ms = mark['start_ms']
                break

    # æå–å¯¹è¯è®°å½•
    transcript_lines = []
    for segment in merged_segments:
        seg_start = segment['start_ms']

        # åˆ¤æ–­ç‰‡æ®µæ˜¯å¦åœ¨ç›®æ ‡æ—¶é—´èŒƒå›´å†…
        if seg_start >= start_ms:
            if end_ms is None or seg_start < end_ms:
                speaker = segment.get('display_speaker', segment.get('speaker', 'æœªçŸ¥'))
                text = segment.get('text', '')
                start_time = segment.get('start', '')
                end_time = segment.get('end', '')
                transcript_lines.append(f"[{start_time}-{end_time}] {speaker}: {text}")
            else:
                break

    return '\n'.join(transcript_lines)


def build_user_prompt(
    user_prompt_template: str,
    match_name: str,
    board_type: str,
    board_config: Dict[str, Any],
    player_info: str,
    no_sheriff: List[str],
    asr_transcript: str,
    prev_analysis: str = ""
) -> str:
    """æ„å»ºç”¨æˆ·prompt

    Args:
        user_prompt_template: ç”¨æˆ·promptæ¨¡æ¿
        match_name: æ¯”èµ›åç§°
        board_type: ç‰ˆå‹åç§°
        board_config: ç‰ˆå‹é…ç½®
        player_info: ç©å®¶ä¿¡æ¯
        no_sheriff: æœªä¸Šè­¦ç©å®¶åˆ—è¡¨
        asr_transcript: ASRå¯¹è¯è®°å½•
        prev_analysis: å‰åºåˆ†æè®°å½•
    """
    roles = board_config.get('roles', '')
    action_seq = board_config.get('action_seq', '')
    rules = board_config.get('rules', '')

    # æ ¼å¼åŒ–æœªä¸Šè­¦ç©å®¶
    no_sheriff_text = 'ã€'.join(no_sheriff) if no_sheriff else 'æ— '

    # å¡«å……æ¨¡æ¿ - ç°åœ¨æœ‰9ä¸ªå‚æ•°
    return user_prompt_template % (
        match_name,
        board_type,
        roles,
        action_seq,
        rules,
        player_info,
        no_sheriff_text,
        asr_transcript,
        prev_analysis
    )


def group_segments_by_speaker(merged_segments: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æŒ‰å‘è¨€äººåˆ†ç»„å¯¹è¯ç‰‡æ®µï¼Œæ¯ä¸ªå‘è¨€äººçš„è¿ç»­å‘è¨€ä½œä¸ºä¸€ç»„
    
    Args:
        merged_segments: åˆå¹¶åçš„å¯¹è¯ç‰‡æ®µåˆ—è¡¨
        
    Returns:
        æŒ‰å‘è¨€äººåˆ†ç»„çš„å‘è¨€åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
        - speaker: å‘è¨€äºº
        - segments: è¯¥å‘è¨€äººçš„è¿ç»­ç‰‡æ®µåˆ—è¡¨
        - transcript: è¯¥å‘è¨€äººçš„å®Œæ•´å‘è¨€æ–‡æœ¬
        - start_time: å¼€å§‹æ—¶é—´
        - end_time: ç»“æŸæ—¶é—´
    """
    if not merged_segments:
        return []
    
    grouped_speeches = []
    current_speaker = None
    current_segments = []
    
    for segment in merged_segments:
        speaker = segment.get('display_speaker', segment.get('speaker', 'æœªçŸ¥'))
        
        # è·³è¿‡æ³•å®˜å’ŒæœªçŸ¥å‘è¨€ï¼ˆå¯é€‰ï¼‰
        if speaker in ['æ³•å®˜', 'æœªçŸ¥']:
            # å¦‚æœæœ‰å½“å‰å‘è¨€äººçš„ç‰‡æ®µï¼Œå…ˆä¿å­˜
            if current_segments:
                grouped_speeches.append({
                    'speaker': current_speaker,
                    'segments': current_segments.copy(),
                    'transcript': '\n'.join(f"[{seg.get('start', '')}-{seg.get('end', '')}] {current_speaker}: {seg.get('text', '')}" for seg in current_segments),
                    'start_time': current_segments[0].get('start', ''),
                    'end_time': current_segments[-1].get('end', ''),
                    'start_ms': current_segments[0].get('start_ms', 0),
                    'end_ms': current_segments[-1].get('end_ms', 0)
                })
                current_segments = []
                current_speaker = None
            continue
            
        if current_speaker != speaker:
            # å‘è¨€äººå˜åŒ–ï¼Œä¿å­˜å‰ä¸€ä¸ªå‘è¨€äººçš„ç‰‡æ®µ
            if current_segments:
                grouped_speeches.append({
                    'speaker': current_speaker,
                    'segments': current_segments.copy(),
                    'transcript': '\n'.join(f"[{seg.get('start', '')}-{seg.get('end', '')}] {current_speaker}: {seg.get('text', '')}" for seg in current_segments),
                    'start_time': current_segments[0].get('start', ''),
                    'end_time': current_segments[-1].get('end', ''),
                    'start_ms': current_segments[0].get('start_ms', 0),
                    'end_ms': current_segments[-1].get('end_ms', 0)
                })
            
            # å¼€å§‹æ–°çš„å‘è¨€äºº
            current_speaker = speaker
            current_segments = [segment]
        else:
            # åŒä¸€å‘è¨€äººï¼Œæ·»åŠ ç‰‡æ®µ
            current_segments.append(segment)
    
    # ä¿å­˜æœ€åä¸€ä¸ªå‘è¨€äººçš„ç‰‡æ®µ
    if current_segments:
        grouped_speeches.append({
            'speaker': current_speaker,
            'segments': current_segments.copy(),
            'transcript': '\n'.join(f"[{seg.get('start', '')}-{seg.get('end', '')}] {current_speaker}: {seg.get('text', '')}" for seg in current_segments),
            'start_time': current_segments[0].get('start', ''),
            'end_time': current_segments[-1].get('end', ''),
            'start_ms': current_segments[0].get('start_ms', 0),
            'end_ms': current_segments[-1].get('end_ms', 0)
        })
    
    return grouped_speeches


def call_openai_api(
    sys_prompt: str,
    user_prompt: str,
    api_key: str,
    base_url: str = None,
    model: str = "gpt-4o",
    temperature: float = 0.7,
    max_tokens: int = 4096
) -> str:
    """è°ƒç”¨OpenAI APIè¿›è¡Œåˆ†æ

    Args:
        sys_prompt: ç³»ç»Ÿprompt
        user_prompt: ç”¨æˆ·prompt
        api_key: OpenAI APIå¯†é’¥
        base_url: APIåŸºç¡€URLï¼ˆå¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰endpointï¼‰
        model: æ¨¡å‹åç§°
        temperature: æ¸©åº¦å‚æ•°
        max_tokens: æœ€å¤§tokenæ•°

    Returns:
        APIè¿”å›çš„åˆ†æç»“æœ
    """
    client_kwargs = {"api_key": api_key}
    if base_url:
        client_kwargs["base_url"] = base_url
    print("client_kwargs: ", client_kwargs)
    client = Ark(**client_kwargs)
    print("user_prompt: ", user_prompt)
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=temperature,
        max_tokens=max_tokens
    )

    return response.choices[0].message.content


def progressive_analysis(
    grouped_speeches: List[Dict[str, Any]],
    sys_prompt: str,
    user_prompt_template: str,
    match_name: str,
    board_type: str,
    board_config: Dict[str, Any],
    player_info: str,
    no_sheriff: List[str],
    api_key: str,
    base_url: str = None,
    model: str = "gpt-4o",
    temperature: float = 0.7,
    max_tokens: int = 4096
) -> str:
    """é€æ®µåˆ†æå‘è¨€
    
    Args:
        grouped_speeches: æŒ‰å‘è¨€äººåˆ†ç»„çš„å‘è¨€åˆ—è¡¨
        sys_prompt: ç³»ç»Ÿprompt
        user_prompt_template: ç”¨æˆ·promptæ¨¡æ¿
        match_name: æ¯”èµ›åç§°
        board_type: ç‰ˆå‹åç§°
        board_config: ç‰ˆå‹é…ç½®
        player_info: ç©å®¶ä¿¡æ¯
        no_sheriff: æœªä¸Šè­¦ç©å®¶åˆ—è¡¨
        api_key: APIå¯†é’¥
        base_url: APIåŸºç¡€URL
        model: æ¨¡å‹åç§°
        temperature: æ¸©åº¦å‚æ•°
        max_tokens: æœ€å¤§tokenæ•°
    
    Returns:
        å®Œæ•´çš„åˆ†æç»“æœ
    """
    all_analysis = []
    prev_analysis = ""
    
    for i, speech in enumerate(grouped_speeches):
        speaker = speech['speaker']
        transcript = speech['transcript']
        
        print(f"\n=== åˆ†æç¬¬ {i+1}/{len(grouped_speeches)} ä½å‘è¨€äºº: {speaker} ===")
        print(f"å‘è¨€æ—¶é—´: {speech['start_time']}-{speech['end_time']}")
        print(f"å‘è¨€å†…å®¹: {transcript[:100]}..." if len(transcript) > 100 else f"å‘è¨€å†…å®¹: {transcript}")
        
        # æ„å»ºå½“å‰è½®æ¬¡çš„prompt
        user_prompt = build_user_prompt(
            user_prompt_template,
            match_name,
            board_type,
            board_config,
            player_info,
            no_sheriff,
            transcript,
            prev_analysis
        )
        
        # è°ƒç”¨APIè¿›è¡Œåˆ†æ
        try:
            current_analysis = call_openai_api(
                sys_prompt,
                user_prompt,
                api_key,
                base_url,
                model,
                temperature,
                max_tokens
            )
            
            # æ·»åŠ åˆ†æç»“æœ
            analysis_section = f"\n=== ç¬¬{i+1}è½®åˆ†æ - {speaker} ===\n{current_analysis}\n"
            all_analysis.append(analysis_section)
            
            # æ›´æ–°å‰åºåˆ†æè®°å½•
            prev_analysis = "\n".join(all_analysis)
            
            print(f"âœ… å®Œæˆ {speaker} çš„åˆ†æ")
            
        except Exception as e:
            print(f"âŒ åˆ†æ {speaker} æ—¶å‡ºé”™: {e}")
            error_section = f"\n=== ç¬¬{i+1}è½®åˆ†æ - {speaker} ===\nåˆ†æå¤±è´¥: {str(e)}\n"
            all_analysis.append(error_section)
    
    return "\n".join(all_analysis)


def save_analysis_result(
    output_path: str,
    analysis_text: str,
    metadata: Dict[str, Any] = None
):
    """ä¿å­˜åˆ†æç»“æœ

    Args:
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        analysis_text: åˆ†ææ–‡æœ¬
        metadata: å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
    """
    # ä¿å­˜JSONæ ¼å¼
    result = {
        "analysis": analysis_text,
        "metadata": metadata or {}
    }

    json_path = output_path.replace('.txt', '.json') if output_path.endswith('.txt') else output_path + '.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    # ä¿å­˜çº¯æ–‡æœ¬æ ¼å¼
    txt_path = output_path.replace('.json', '.txt') if output_path.endswith('.json') else output_path + '.txt'
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(analysis_text)

    print(f"åˆ†æç»“æœå·²ä¿å­˜:")
    print(f"  JSON: {json_path}")
    print(f"  TXT:  {txt_path}")


def main():
    parser = argparse.ArgumentParser(description='ç‹¼äººæ€æ¯”èµ›åˆ†æè„šæœ¬ï¼ˆç®€åŒ–ç‰ˆï¼‰')
    parser.add_argument('asr_log', help='ASRæ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º analysis/{bv_id}_sheriff_election.txtï¼‰')

    args = parser.parse_args()

    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    api_key = os.environ.get('OPENAI_API_KEY')
    base_url = os.environ.get('OPENAI_BASE_URL')
    model = os.environ.get('OPENAI_MODEL', 'gpt-4o')
    temperature = float(os.environ.get('OPENAI_TEMPERATURE', '0.7'))
    max_tokens = int(os.environ.get('OPENAI_MAX_TOKENS', '4096'))
    board_config_path = os.environ.get('BOARD_CONFIG_PATH', 'configs/board_config.json')

    if not api_key:
        raise ValueError("å¿…é¡»è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")

    # åŠ è½½ASRæ—¥å¿—
    print("åŠ è½½ASRæ—¥å¿—...")
    asr_data = load_asr_log(args.asr_log)

    # ä»ASRæ—¥å¿—ä¸­è¯»å–ä¿¡æ¯
    match_name = asr_data.get('match_name', 'æœªå‘½åæ¯”èµ›')
    board_type = asr_data.get('board_type', 'æœªçŸ¥ç‰ˆå‹')
    video_name = asr_data.get('video_name', 'unknown')
    speaker_roles = asr_data.get('speaker_roles', {})
    speaker_seqs = asr_data.get('speaker_seqs', {})
    no_sheriff = asr_data.get('no_sheriff', [])
    time_marks = asr_data.get('time_marks', [])

    print("=== ç‹¼äººæ€æ¯”èµ›åˆ†æ ===")
    print(f"æ¯”èµ›åç§°: {match_name}")
    print(f"ç‰ˆå‹: {board_type}")
    print(f"ASRæ—¥å¿—: {args.asr_log}")
    print(f"æ¨¡å‹: {model}")

    # å›ºå®šåˆ†ææ—¶æ®µï¼šç¬¬ä¸€å¤©-ç™½å¤©-è­¦å¾½ç«é€‰ï¼ˆè­¦ä¸Šï¼‰åˆ°ä¸‹ä¸€ä¸ªsection
    section_start = "ç¬¬ä¸€å¤©-ç™½å¤©-è­¦å¾½ç«é€‰ï¼ˆè­¦ä¸Šï¼‰"

    # æŸ¥æ‰¾å¼€å§‹æ ‡è®°
    start_mark = None
    next_mark = None

    for i, mark in enumerate(time_marks):
        if section_start in mark.get('label', ''):
            start_mark = mark
            # æ‰¾åˆ°ä¸‹ä¸€ä¸ªæ ‡è®°ä½œä¸ºç»“æŸ
            if i + 1 < len(time_marks):
                next_mark = time_marks[i + 1]
            break

    if start_mark is None:
        raise ValueError(f"æœªæ‰¾åˆ°æ—¶é—´æ ‡è®°: {section_start}")

    if next_mark:
        print(f"åˆ†ææ—¶æ®µ: {start_mark['label']} -> {next_mark['label']}")
        section_label = "sheriff_election"
    else:
        print(f"åˆ†ææ—¶æ®µ: {start_mark['label']} -> (ç»“æŸ)")
        section_label = "sheriff_election_to_end"

    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if not args.output:
        os.makedirs('analysis', exist_ok=True)
        args.output = f"analysis/{video_name}_{section_label}.txt"

    print(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    print()

    # 1. åŠ è½½prompts
    print("åŠ è½½prompts...")
    sys_prompt, user_prompt_template = load_prompts()

    # 2. åŠ è½½ç‰ˆå‹é…ç½®
    print("åŠ è½½ç‰ˆå‹é…ç½®...")
    board_configs = load_board_config(board_config_path)
    if board_type not in board_configs:
        raise ValueError(f"ç‰ˆå‹ '{board_type}' ä¸å­˜åœ¨äºé…ç½®æ–‡ä»¶ä¸­ã€‚å¯ç”¨ç‰ˆå‹: {list(board_configs.keys())}")
    board_config = board_configs[board_type]

    # 3. æå–å¯¹è¯è®°å½•
    print("æå–å¯¹è¯è®°å½•...")
    # æ‰¾åˆ°ç›®æ ‡æ—¶é—´æ®µå†…çš„segments
    target_segments = []
    start_ms = start_mark['start_ms']
    end_ms = next_mark['start_ms'] if next_mark else None
    
    for segment in asr_data.get('merged_segments', []):
        seg_start = segment['start_ms']
        if seg_start >= start_ms:
            if end_ms is None or seg_start < end_ms:
                target_segments.append(segment)
            else:
                break
    
    print(f"æå–åˆ° {len(target_segments)} ä¸ªå¯¹è¯ç‰‡æ®µ")
    
    # æŒ‰å‘è¨€äººåˆ†ç»„
    print("æŒ‰å‘è¨€äººåˆ†ç»„å¯¹è¯...")
    grouped_speeches = group_segments_by_speaker(target_segments)
    print(f"åˆ†ç»„åå…± {len(grouped_speeches)} ä½å‘è¨€äºº")
    
    # æ˜¾ç¤ºå‘è¨€é¡ºåº
    print("å‘è¨€é¡ºåº:")
    for i, speech in enumerate(grouped_speeches):
        print(f"  ç¬¬{i+1}ä½: {speech['speaker']} ({speech['start_time']}-{speech['end_time']})")

    # 4. æ„å»ºç©å®¶ä¿¡æ¯
    print("æ„å»ºç©å®¶ä¿¡æ¯...")
    player_info_lines = []

    # æŒ‰åºå·æ’åº
    players = [(seq, name) for name, seq in speaker_seqs.items() if seq and seq != 'æ— ' and name != 'æ³•å®˜']

    # ç®€å•æ’åºï¼ˆä¸€å·ã€äºŒå·...ï¼‰
    def seq_sort_key(item):
        seq = item[0]
        num_map = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
                   'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
                   'åä¸€': 11, 'åäºŒ': 12}
        return num_map.get(seq.replace('å·', ''), 99)

    players.sort(key=seq_sort_key)

    # æ„å»ºç©å®¶ä¿¡æ¯ï¼ˆä¸æ˜¾ç¤ºèº«ä»½ï¼Œä¿æŒç¬¬ä¸‰æ–¹åˆ†æè§†è§’ï¼‰
    for seq, name in players:
        player_info_lines.append(f"{seq} {name}")

    # æ·»åŠ æ³•å®˜
    for name, seq in speaker_seqs.items():
        if name == 'æ³•å®˜':
            player_info_lines.append(f"æ³•å®˜ {name}")
            break

    player_info = '\n'.join(player_info_lines)

    # è°ƒè¯•è¾“å‡º
    print(f"æ„å»ºçš„ç©å®¶ä¿¡æ¯:")
    for line in player_info_lines:
        print(f"  {line}")
    print(f"æœªä¸Šè­¦ç©å®¶: {no_sheriff}")

    # 5. é€æ®µåˆ†æ
    print("å¼€å§‹é€æ®µåˆ†æ...")
    analysis_result = progressive_analysis(
        grouped_speeches,
        sys_prompt,
        user_prompt_template,
        match_name,
        board_type,
        board_config,
        player_info,
        no_sheriff,
        api_key,
        base_url,
        model,
        temperature,
        max_tokens
    )

    print("\nğŸ‰ æ‰€æœ‰å‘è¨€åˆ†æå®Œæˆï¼")

    # 7. ä¿å­˜ç»“æœ
    metadata = {
        "match_name": match_name,
        "board_type": board_type,
        "asr_log": args.asr_log,
        "section_start": start_mark['label'] if start_mark else None,
        "section_end": next_mark['label'] if next_mark else None,
        "model": model,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "analysis_type": "progressive",
        "total_speakers": len(grouped_speeches),
        "speakers": [speech['speaker'] for speech in grouped_speeches]
    }

    save_analysis_result(args.output, analysis_result, metadata)

    print("\n=== å¤„ç†å®Œæˆ ===")


if __name__ == "__main__":
    main()