#!/usr/bin/env python3
"""
ç‹¼äººæ€åˆ†æå£è¯­åŒ–è§£è¯´è„šæœ¬
å°†é€æ®µåˆ†æç»“æœè½¬æ¢ä¸ºå£è¯­åŒ–çš„ç«æŠ€è§£è¯´é£æ ¼
"""

import os
import json
import argparse
import re
from typing import Dict, Any, List
from volcenginesdkarkruntime import Ark
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()


def load_prompts():
    """åŠ è½½ pmt.py ä¸­çš„å£è¯­åŒ–è§£è¯´ prompt"""
    import pmt
    return pmt.sys_pmt_oral, pmt.user_pmt_oral


def load_analysis_file(analysis_path: str) -> str:
    """åŠ è½½åˆ†ææ–‡ä»¶"""
    with open(analysis_path, 'r', encoding='utf-8') as f:
        return f.read()


def load_config_json(config_path: str) -> Dict[str, Any]:
    """åŠ è½½ASRé…ç½®JSONæ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def load_board_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½ç‰ˆå‹é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def split_analysis_by_rounds(analysis_text: str) -> List[Dict[str, Any]]:
    """æŒ‰è½®æ¬¡åˆ†å‰²åˆ†æç»“æœ
    
    Args:
        analysis_text: å®Œæ•´çš„åˆ†ææ–‡æœ¬
        
    Returns:
        è½®æ¬¡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
        - round_num: è½®æ¬¡ç¼–å·
        - speaker: å‘è¨€äºº
        - content: åˆ†æå†…å®¹
    """
    rounds = []
    
    # åŒ¹é…æ¨¡å¼ï¼š=== ç¬¬Xè½®åˆ†æ - å‘è¨€äºº ===
    pattern = r'=== ç¬¬(\d+)è½®åˆ†æ - (.+?) ===\n(.*?)(?=\n=== ç¬¬\d+è½®åˆ†æ -|\Z)'
    
    matches = re.finditer(pattern, analysis_text, re.DOTALL)
    
    for match in matches:
        round_num = int(match.group(1))
        speaker = match.group(2).strip()
        content = match.group(3).strip()
        
        rounds.append({
            'round_num': round_num,
            'speaker': speaker,
            'content': content
        })
    
    return rounds


def build_oral_sys_prompt(
    sys_prompt_template: str,
    match_name: str,
    board_type: str,
    board_config: Dict[str, Any],
    player_info: str,
    no_sheriff: List[str]
) -> str:
    """æ„å»ºå£è¯­åŒ–è§£è¯´çš„ç³»ç»Ÿprompt
    
    Args:
        sys_prompt_template: ç³»ç»Ÿpromptæ¨¡æ¿
        match_name: æ¯”èµ›åç§°
        board_type: ç‰ˆå‹åç§°
        board_config: ç‰ˆå‹é…ç½®
        player_info: ç©å®¶ä¿¡æ¯
        no_sheriff: æœªä¸Šè­¦ç©å®¶åˆ—è¡¨
    """
    roles = board_config.get('roles', '')
    action_seq = board_config.get('action_seq', '')
    rules = board_config.get('rules', '')
    
    # æ ¼å¼åŒ–æœªä¸Šè­¦ç©å®¶
    no_sheriff_text = 'ã€'.join(no_sheriff) if no_sheriff else 'æ— '
    
    # å¡«å……ç³»ç»Ÿpromptæ¨¡æ¿
    return sys_prompt_template % (
        match_name,
        board_type,
        roles,
        action_seq,
        rules,
        player_info,
        no_sheriff_text
    )


def build_oral_user_prompt(
    user_prompt_template: str,
    analysis_content: str
) -> str:
    """æ„å»ºå£è¯­åŒ–è§£è¯´çš„ç”¨æˆ·prompt
    
    Args:
        user_prompt_template: ç”¨æˆ·promptæ¨¡æ¿
        analysis_content: åˆ†æå†…å®¹
    """
    return user_prompt_template % analysis_content


def call_openai_api(
    sys_prompt: str,
    user_prompt: str,
    api_key: str,
    base_url: str = None,
    model: str = "gpt-4o",
    temperature: float = 0.8,
    max_tokens: int = 2048
) -> str:
    """è°ƒç”¨OpenAI APIè¿›è¡Œå£è¯­åŒ–è½¬æ¢"""
    client_kwargs = {"api_key": api_key}
    if base_url:
        client_kwargs["base_url"] = base_url
    
    client = Ark(**client_kwargs)
    
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=temperature,
        max_tokens=max_tokens
    )
    
    return response.choices[0].message.content


def extract_commentary(response: str) -> str:
    """ä»å“åº”ä¸­æå–è§£è¯´å†…å®¹"""
    # å°è¯•æå– <commentary> æ ‡ç­¾å†…çš„å†…å®¹
    match = re.search(r'<commentary>(.*?)</commentary>', response, re.DOTALL)
    if match:
        return match.group(1).strip()
    return response.strip()


def progressive_oral_commentary(
    rounds: List[Dict[str, Any]],
    sys_prompt: str,
    user_prompt_template: str,
    api_key: str,
    base_url: str = None,
    model: str = "gpt-4o",
    temperature: float = 0.8,
    max_tokens: int = 2048
) -> List[Dict[str, Any]]:
    """é€è½®ç”Ÿæˆå£è¯­åŒ–è§£è¯´
    
    Args:
        rounds: åˆ†æè½®æ¬¡åˆ—è¡¨
        sys_prompt: ç³»ç»Ÿprompt
        user_prompt_template: ç”¨æˆ·promptæ¨¡æ¿
        api_key: APIå¯†é’¥
        base_url: APIåŸºç¡€URL
        model: æ¨¡å‹åç§°
        temperature: æ¸©åº¦å‚æ•°
        max_tokens: æœ€å¤§tokenæ•°
    
    Returns:
        åŒ…å«å£è¯­åŒ–è§£è¯´çš„è½®æ¬¡åˆ—è¡¨
    """
    oral_results = []
    
    for round_data in rounds:
        round_num = round_data['round_num']
        speaker = round_data['speaker']
        content = round_data['content']
        
        print(f"\n=== è½¬æ¢ç¬¬ {round_num} è½®è§£è¯´ - {speaker} ===")
        
        # æ„å»ºç”¨æˆ·prompt
        user_prompt = build_oral_user_prompt(user_prompt_template, content)
        
        try:
            # è°ƒç”¨API
            response = call_openai_api(
                sys_prompt,
                user_prompt,
                api_key,
                base_url,
                model,
                temperature,
                max_tokens
            )
            
            # æå–è§£è¯´å†…å®¹
            commentary = extract_commentary(response)
            
            oral_results.append({
                'round_num': round_num,
                'speaker': speaker,
                'original_analysis': content,
                'oral_commentary': commentary
            })
            
            print(f"âœ… å®Œæˆ {speaker} çš„è§£è¯´è½¬æ¢")
            print(f"è§£è¯´é¢„è§ˆ: {commentary[:100]}...")
            
        except Exception as e:
            print(f"âŒ è½¬æ¢ {speaker} è§£è¯´æ—¶å‡ºé”™: {e}")
            oral_results.append({
                'round_num': round_num,
                'speaker': speaker,
                'original_analysis': content,
                'oral_commentary': f"[è§£è¯´ç”Ÿæˆå¤±è´¥: {str(e)}]"
            })
    
    return oral_results


def save_oral_results(
    output_path: str,
    oral_results: List[Dict[str, Any]],
    metadata: Dict[str, Any] = None
):
    """ä¿å­˜å£è¯­åŒ–è§£è¯´ç»“æœ
    
    Args:
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        oral_results: å£è¯­åŒ–è§£è¯´ç»“æœåˆ—è¡¨
        metadata: å…ƒæ•°æ®
    """
    # ä¿å­˜JSONæ ¼å¼
    result = {
        "oral_commentary": oral_results,
        "metadata": metadata or {}
    }
    
    json_path = output_path.replace('.txt', '.json') if output_path.endswith('.txt') else output_path + '.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜çº¯æ–‡æœ¬æ ¼å¼
    txt_path = output_path.replace('.json', '.txt') if output_path.endswith('.json') else output_path + '.txt'
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write("=== ç‹¼äººæ€æ¯”èµ›å£è¯­åŒ–è§£è¯´ ===\n\n")
        
        for item in oral_results:
            f.write(f"ã€ç¬¬{item['round_num']}è½® - {item['speaker']}ã€‘\n")
            f.write(f"{item['oral_commentary']}\n\n")
            f.write("-" * 80 + "\n\n")
    
    print(f"\nå£è¯­åŒ–è§£è¯´å·²ä¿å­˜:")
    print(f"  JSON: {json_path}")
    print(f"  TXT:  {txt_path}")


def build_player_info(config_data: Dict[str, Any]) -> str:
    """ä»é…ç½®æ•°æ®æ„å»ºç©å®¶ä¿¡æ¯"""
    speaker_seqs = config_data.get('speaker_seqs', {})
    
    player_info_lines = []
    
    # æŒ‰åºå·æ’åº
    players = [(seq, name) for name, seq in speaker_seqs.items() if seq and seq != 'æ— ' and name != 'æ³•å®˜']
    
    def seq_sort_key(item):
        seq = item[0]
        num_map = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
                   'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
                   'åä¸€': 11, 'åäºŒ': 12}
        return num_map.get(seq.replace('å·', ''), 99)
    
    players.sort(key=seq_sort_key)
    
    for seq, name in players:
        player_info_lines.append(f"{seq} {name}")
    
    # æ·»åŠ æ³•å®˜
    for name, seq in speaker_seqs.items():
        if name == 'æ³•å®˜':
            player_info_lines.append(f"æ³•å®˜ {name}")
            break
    
    return '\n'.join(player_info_lines)


def main():
    parser = argparse.ArgumentParser(description='ç‹¼äººæ€åˆ†æå£è¯­åŒ–è§£è¯´è„šæœ¬')
    parser.add_argument('analysis_file', help='åˆ†ææ–‡æœ¬æ–‡ä»¶è·¯å¾„ï¼ˆstep_10è¾“å‡ºçš„txtæ–‡ä»¶ï¼‰')
    parser.add_argument('config_json', help='åŸå§‹ASRé…ç½®JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º oral/{video_name}_oral.txtï¼‰')
    
    args = parser.parse_args()
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    api_key = os.environ.get('OPENAI_API_KEY')
    base_url = os.environ.get('OPENAI_BASE_URL')
    model = os.environ.get('OPENAI_MODEL', 'gpt-4o')
    temperature = float(os.environ.get('OPENAI_TEMPERATURE_ORAL', '0.8'))
    max_tokens = int(os.environ.get('OPENAI_MAX_TOKENS_ORAL', '2048'))
    board_config_path = os.environ.get('BOARD_CONFIG_PATH', 'configs/board_config.json')
    
    if not api_key:
        raise ValueError("å¿…é¡»è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
    
    print("=== ç‹¼äººæ€åˆ†æå£è¯­åŒ–è§£è¯´ ===")
    print(f"åˆ†ææ–‡ä»¶: {args.analysis_file}")
    print(f"é…ç½®æ–‡ä»¶: {args.config_json}")
    print(f"æ¨¡å‹: {model}")
    print()
    
    # 1. åŠ è½½åˆ†ææ–‡ä»¶
    print("åŠ è½½åˆ†ææ–‡ä»¶...")
    analysis_text = load_analysis_file(args.analysis_file)
    
    # 2. åˆ†å‰²åˆ†æè½®æ¬¡
    print("åˆ†å‰²åˆ†æè½®æ¬¡...")
    rounds = split_analysis_by_rounds(analysis_text)
    print(f"æ‰¾åˆ° {len(rounds)} è½®åˆ†æ")
    
    if not rounds:
        print("âŒ æœªæ‰¾åˆ°åˆ†æè½®æ¬¡ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
        return 1
    
    # 3. åŠ è½½é…ç½®
    print("åŠ è½½é…ç½®ä¿¡æ¯...")
    config_data = load_config_json(args.config_json)
    
    match_name = config_data.get('match_name', 'æœªå‘½åæ¯”èµ›')
    board_type = config_data.get('board_type', 'æœªçŸ¥ç‰ˆå‹')
    video_name = config_data.get('video_name', 'unknown')
    no_sheriff = config_data.get('no_sheriff', [])
    
    # 4. åŠ è½½ç‰ˆå‹é…ç½®
    print("åŠ è½½ç‰ˆå‹é…ç½®...")
    board_configs = load_board_config(board_config_path)
    if board_type not in board_configs:
        raise ValueError(f"ç‰ˆå‹ '{board_type}' ä¸å­˜åœ¨äºé…ç½®æ–‡ä»¶ä¸­")
    board_config = board_configs[board_type]
    
    # 5. æ„å»ºç©å®¶ä¿¡æ¯
    print("æ„å»ºç©å®¶ä¿¡æ¯...")
    player_info = build_player_info(config_data)
    
    # 6. åŠ è½½å£è¯­åŒ–è§£è¯´prompts
    print("åŠ è½½è§£è¯´prompts...")
    sys_prompt_template, user_prompt_template = load_prompts()
    
    # 7. æ„å»ºç³»ç»Ÿprompt
    sys_prompt = build_oral_sys_prompt(
        sys_prompt_template,
        match_name,
        board_type,
        board_config,
        player_info,
        no_sheriff
    )
    
    # 8. ç¡®å®šè¾“å‡ºè·¯å¾„
    if not args.output:
        os.makedirs('oral', exist_ok=True)
        args.output = f"oral/{video_name}_oral.txt"
    
    print(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    print()
    
    # 9. é€è½®ç”Ÿæˆå£è¯­åŒ–è§£è¯´
    print("å¼€å§‹ç”Ÿæˆå£è¯­åŒ–è§£è¯´...")
    oral_results = progressive_oral_commentary(
        rounds,
        sys_prompt,
        user_prompt_template,
        api_key,
        base_url,
        model,
        temperature,
        max_tokens
    )
    
    print("\nğŸ‰ æ‰€æœ‰è§£è¯´ç”Ÿæˆå®Œæˆï¼")
    
    # 10. ä¿å­˜ç»“æœ
    metadata = {
        "match_name": match_name,
        "board_type": board_type,
        "video_name": video_name,
        "analysis_file": args.analysis_file,
        "config_json": args.config_json,
        "model": model,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "total_rounds": len(oral_results)
    }
    
    save_oral_results(args.output, oral_results, metadata)
    
    print("\n=== å¤„ç†å®Œæˆ ===")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

